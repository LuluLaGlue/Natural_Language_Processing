{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Extract Cities From a Text Using NLP"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Listing Nouns in a string"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "doc = nlp(\"Bonjour je viens de Paris et je suis Lucien. En France il y a l'aéroport d'Orly à Paris et Saint-Exupéry à Lyon.\")\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        print(token.text, token.pos_, token.dep_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Paris PROPN obl:arg\n",
      "Lucien PROPN conj\n",
      "France PROPN obl:mod\n",
      "Orly PROPN nmod\n",
      "Paris PROPN nmod\n",
      "Saint-Exupéry PROPN conj\n",
      "Lyon PROPN obl:mod\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Listing Locations in the same string"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences \n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    "\n",
    "doc = nlp(\"Bonjour je viens de Paris et je suis Lucien. En France il y a l'aéroport d'Orly à Paris et Saint-Exupéry à Lyon.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\":\n",
    "        print(ent.text, ent.label_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Paris LOC\n",
      "France LOC\n",
      "aéroport d'Orly LOC\n",
      "Paris LOC\n",
      "Saint-Exupéry LOC\n",
      "Lyon LOC\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Listing Locations From an Article"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from newspaper import Article\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    "\n",
    "url = r\"https://www.lemonde.fr/societe/article/2021/09/14/emmanuel-macron-clot-le-beauvau-de-la-securite-l-elysee-promet-des-annonces-substantielles_6094578_3224.html\"\n",
    "\n",
    "article = Article(url)\n",
    "article.download()\n",
    "article.parse()\n",
    "\n",
    "doc = nlp(article.text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\":\n",
    "        print(ent.text, ent.label_)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Listing Locations From a Text File"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    "\n",
    "file = open(\"../data/txt/text.txt\", \"r\").read().lower() # Lower Case Helps w/ Detection\n",
    "\n",
    "doc = nlp(file)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\":\n",
    "        print(ent.text[0].upper() + ent.text[1:], ent.label_)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# How to extract Cities from this list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Method One: BruteForce\n",
    "#### If it's not a country or a continent it's a city"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    "\n",
    "file = open(\"../data/txt/text.txt\", \"r\").read().lower() # Lower Case Helps w/ Detection\n",
    "\n",
    "doc = nlp(file)\n",
    "places = []\n",
    "countries = []\n",
    "res = []\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\":\n",
    "        places.append(ent.text)\n",
    "\n",
    "data = pd.read_csv(\"../data/csv/pays.csv\", sep=\";\")\n",
    "\n",
    "for country in data[\"nom\"]:\n",
    "    countries.append(country.lower())\n",
    "\n",
    "for loc in places:\n",
    "    if loc not in countries:\n",
    "        res.append(loc)\n",
    "\n",
    "print(res)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-  _This method kinda works but if a region is given it will output it as a City._\n",
    "-  _Furthermore, if the country is not perfectly written (e.g. Tanzania instead of United Republic Of Tanzania) it will consider it as a City._"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Methode Two: geonamescache\n",
    "#### if it exists it's a city"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import geonamescache\n",
    "import spacy\n",
    "\n",
    "gc = geonamescache.GeonamesCache()\n",
    "# cities = gc.search_cities(\"Lyon\")\n",
    "# print(cities)\n",
    "\n",
    "nlp = spacy.load('fr_core_news_lg')\n",
    " # Can change that based on language\n",
    "\n",
    "file = open(\"../data/txt/text3.txt\", \"r\").read().lower() # Lower Case Helps w/ Detection\n",
    "doc = nlp(file)\n",
    "# file = None\n",
    "list_cities = gc.get_cities()\n",
    "all_cities = []\n",
    "cities = []\n",
    "\n",
    "for city in list_cities:\n",
    "    all_cities.append(list_cities[city]['name'].lower())\n",
    "    for alternate in list_cities[city]['alternatenames']:\n",
    "        dash = alternate.split('-')\n",
    "        dash = ' '.join(dash).lower()\n",
    "        all_cities.append(dash)\n",
    "list_cities = None\n",
    "\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\":\n",
    "        location = ent.text.split('-')\n",
    "        location = \" \".join(location).lower()\n",
    "        if location in all_cities:\n",
    "            cities.append(location)\n",
    "print(cities)\n",
    "print(\"Found {} cities\".format(len(cities)))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'geonameid': 2996944, 'name': 'Lyon', 'latitude': 45.74846, 'longitude': 4.84671, 'countrycode': 'FR', 'population': 472317, 'timezone': 'Europe/Paris', 'admin1code': '84', 'alternatenames': ['LYS', 'Leon do Roine', 'León do Roine', 'Lijon', 'Lio', 'Lion', 'Liona', 'Lionas', 'Lione', 'Lioni', 'Liono', 'Liun', 'Liyon', 'Lió', 'Lión', 'Lugdunum', 'Lyon', 'Lyons', 'li ang', 'li yng', \"li'om\", \"li'ona\", 'lion', 'liong', 'lioni', 'liyon', 'lyom', 'lywn', 'riyon', 'Λυών', 'Лион', 'Ліон', 'Ліён', 'Լիոն', 'ליאן', 'ליון', 'ليون', 'لیون', 'لیۆن', 'ल्यों', 'ਲਿਓਂ', 'ଲିଓନ', 'லியோன்', 'ลียง', 'ལི་ཡོང་།', 'လီယွန်းမြို့', 'ლიონი', 'ልዮን', 'リヨン', '里昂', '리옹']}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-   _It's already better_\n",
    "-   _Depends a lot on the model's precision_\n",
    "-   _Seems a bit heavy_"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.12 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "e6f29abc0f047e6cfd031f1f54b9dedc2d3cf2c312cab46d813dd922dddc4914"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}